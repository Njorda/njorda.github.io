<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Njord tech blog</title><link>https://Njorda.github.io/post/</link><description>Recent content in Posts on Njord tech blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 01 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://Njorda.github.io/post/index.xml" rel="self" type="application/rss+xml"/><item><title>Trition with post and pre processing</title><link>https://Njorda.github.io/2023/02/01/Trition_with_post_and_pre_processing/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/01/Trition_with_post_and_pre_processing/</guid><description>Trition with post and pre processing. This is based upon this repo
In this blog post we will dig down in to how a Machine Learning(ML) model can be combined with pre and post processing steps using Nvidia triton. By combining the pre- and post processing the user can make a single call using GPRC or http. It should be noted that we in reality will not merge these processing steps in any way but link the calls together using Tritons ensemble functionality Triton support multiple different backends(processing functionality) and in this case we will use the tensorRT backend for the model serving and the python backend to add the pre and post processing business logic.</description></item><item><title>Welcome to the Blog</title><link>https://Njorda.github.io/2022/07/17/hello-world/</link><pubDate>Sun, 17 Jul 2022 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2022/07/17/hello-world/</guid><description> “Yeah It&amp;rsquo;s on. ”
Hello World!</description></item></channel></rss>