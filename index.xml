<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Njord tech blog</title><link>https://Njorda.github.io/</link><description>Recent content on Njord tech blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 17 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://Njorda.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Welcome to the Blog</title><link>https://Njorda.github.io/2022/07/17/hello-world/</link><pubDate>Sun, 17 Jul 2022 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2022/07/17/hello-world/</guid><description> “Yeah It&amp;rsquo;s on. ”
Hello World!</description></item><item><title/><link>https://Njorda.github.io/homepage/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/homepage/about/</guid><description>About Me N is a Software engineer working on data processing and distributed systems. Here we go
J is a Machine Learning engineer. Here we go</description></item><item><title/><link>https://Njorda.github.io/post/2022-02-01-triton-ensemble/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/post/2022-02-01-triton-ensemble/</guid><description>Trition with post and pre processing. This is based upon this repo
In this blog post we will dig down in to how a Machine Learning(ML) model can be combined with pre and post processing steps using Nvidia triton. By combining the pre- and post processing the user can make a single call using GPRC or http. It should be noted that we in reality will not merge these processing steps in any way but link the calls together using Tritons ensemble functionality Triton support multiple different backends(processing functionality) and in this case we will use the tensorRT backend for the model serving and the python backend to add the pre and post processing business logic.</description></item></channel></rss>