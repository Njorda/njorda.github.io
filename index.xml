<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Njord tech blog</title><link>https://Njorda.github.io/</link><description>Recent content on Njord tech blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 18 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://Njorda.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Supercharge Your Development Workflow with VS Code Dev Containers</title><link>https://Njorda.github.io/2023/03/18/dev-containers/</link><pubDate>Sat, 18 Mar 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/03/18/dev-containers/</guid><description>VS docker Dev Container Are you tired of dealing with messy, inconsistent development environments that slow down your workflow? Look no further than VS Code dev containers, a powerful feature in Visual Studio Code that can streamline your development process and improve consistency across different environments.
In this post, we&amp;rsquo;ll dive into what dev containers are and how you can use them to supercharge your development workflow. We&amp;rsquo;ll also walk through how to set up a dev container for a Python environment and you will get an understsnding how easy it is to get started.</description></item><item><title>Postgress extention using ChatGPT3</title><link>https://Njorda.github.io/2023/03/11/postgress_extention_using_chatgpt3/</link><pubDate>Sat, 11 Mar 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/03/11/postgress_extention_using_chatgpt3/</guid><description>This blog post will dive into building postgres extensions using pgx in rust. In order to do something existing we will ride the hype curve and integrate ChatGPT3 into postgres.
TLDR: repo
Setup First step is to set up pgx:
$ cargo install --locked cargo-pgx $ cargo pgx init We will then create a new create using:
$ cargo pgx new my_extension $ cd my_extension Which should give you something like:</description></item><item><title>Go memory arena</title><link>https://Njorda.github.io/2023/03/01/go_memory_arena/</link><pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/03/01/go_memory_arena/</guid><description>As part of the go 1.20 release memory areas where introduced to the standard lib but not mentioned in the release notes but is still being discussed as of 2023-03-02 here. Memory arenas allow users to allocate memory and are described by the docs as:
The arena package provides the ability to allocate memory for a collection of Go values and free that space manually all at once, safely. The purpose of this functionality is to improve efficiency: manually freeing memory before a garbage collection delays that cycle.</description></item><item><title>Triton shared memory and pinned memory</title><link>https://Njorda.github.io/2023/02/25/triton_shared_memory/</link><pubDate>Sat, 25 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/25/triton_shared_memory/</guid><description>This blog post will go in to depth how to use shared memory together with nvidia triton and pinned memory for model serving. This will continue to build further on the other blog posts related to triton. First we will focuse on shared memory and then move over to also look in to pinned memory and why it matters.
Shared memory In the triton examples(python) shared memory is often abbreviated as shm.</description></item><item><title>Duckdb with hugo</title><link>https://Njorda.github.io/2023/02/06/hugo-duckdb/</link><pubDate>Wed, 08 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/06/hugo-duckdb/</guid><description>Current hack to just get the stuff working.</description></item><item><title>Go compiler optimizations</title><link>https://Njorda.github.io/2023/02/08/Profile-guided_inlining_optimization/</link><pubDate>Wed, 08 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/08/Profile-guided_inlining_optimization/</guid><description>This is based upon the new feature released in go v1.20 where the compiler can optimize using a pprof file.
In order to run the pprof we will use flags:
flag.Parse() if *cpuprofile != &amp;#34;&amp;#34; { f, err := os.Create(*cpuprofile) if err != nil { log.Fatal(err) } pprof.StartCPUProfile(f) defer pprof.StopCPUProfile() } more info can be found here.
In order to run the profiling use the following command:
go run main.go -cpuprofile=prof.</description></item><item><title>Shinylive app with hugo</title><link>https://Njorda.github.io/2023/02/06/hugo-with-python-rshiny/</link><pubDate>Mon, 06 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/06/hugo-with-python-rshiny/</guid><description>Shinylive app with hugo This blog post is based upon RamiKrispin/shinylive where we will take a look in to using Shiny with python and leveraging WebAssembly to let it run in the browser with out a backend. This allows for interactive static webpages.
In order to add the a shiny app it needs to be deployed, in this case that is handled through github pages and lives within https://github.com/NikeNano/shinylive. The second step is to add the iframe:</description></item><item><title>Trition with post and pre processing</title><link>https://Njorda.github.io/2023/02/01/Trition_with_post_and_pre_processing/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/01/Trition_with_post_and_pre_processing/</guid><description>Trition with post and pre processing. This is based upon this repo
In this blog post we will dig down in to how a Machine Learning(ML) model can be combined with pre and post processing steps using Nvidia triton. By combining the pre- and post processing the user can make a single call using GPRC or http. It should be noted that we in reality will not merge these processing steps in any way but link the calls together using Tritons ensemble functionality Triton support multiple different backends(processing functionality) and in this case we will use the tensorRT backend for the model serving and the python backend to add the pre and post processing business logic.</description></item><item><title>Trition with post and pre processing</title><link>https://Njorda.github.io/2023/02/01/Trition_with_post_and_pre_processing/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/01/Trition_with_post_and_pre_processing/</guid><description>Prompt engineering With the rise of GPT-3 and Stable diffusion the concpet of promt engineering has gain more and more traction. According to wikipedia the task can be described as
Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called &amp;ldquo;prompt-based learning&amp;rdquo; or just &amp;ldquo;prompt learning&amp;rdquo;
Wikipedia Prompts are inputs for models that expect text as input however the output can very most famously images or text.</description></item><item><title>Welcome to the Blog</title><link>https://Njorda.github.io/2022/07/17/hello-world/</link><pubDate>Sun, 17 Jul 2022 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2022/07/17/hello-world/</guid><description> ‚ÄúYeah It&amp;rsquo;s on. ‚Äù
Hello World!</description></item><item><title/><link>https://Njorda.github.io/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/about/</guid><description>Niklas Niklas is a Software engineer(previously data scientist) working with battery manufacturing üîã . He loves learning new things and currently work on traceability for electrode manufacturing. Work is GO, python and SQL while night hacking currently is rust.
Some open source project Niklas has contributed to:
kubeflow pipelines argo workflows nvidia triton Niklas Johan is a Machine Learning engineer working on forecasting and life time value forecasting üîé .</description></item><item><title/><link>https://Njorda.github.io/posts/2023-02-07-poor_mans_datalake/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/posts/2023-02-07-poor_mans_datalake/</guid><description>Poor mans datalake layout: post title: &amp;ldquo;Poor mans datalake&amp;rdquo; subtitle: &amp;ldquo;DuckDb&amp;rdquo; date: 2023-02-01 author: &amp;ldquo;Niklas Hansson&amp;rdquo; URL: &amp;ldquo;/2023/02/01/Trition_with_post_and_pre_processing/&amp;rdquo; This post is a deep dive playing with DuckDB doing a twist on Build a poor man‚Äôs data lake from scratch with DuckDB where we will do the following changes:
Use Minio instead of S3 DBT instead of dagster. We will host it on Kubernetes and set it up so it all run locally.</description></item></channel></rss>