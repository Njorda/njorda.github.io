<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Njord tech blog</title><link>https://www.njordy.com/</link><description>Recent content on Njord tech blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 19 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://www.njordy.com/index.xml" rel="self" type="application/rss+xml"/><item><title>DBOS: A Database-Oriented Operating System</title><link>https://www.njordy.com/2023/05/19/operating_system_databases/</link><pubDate>Fri, 19 May 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/05/19/operating_system_databases/</guid><description>A group of researches are proposing a radical change of the future operating system. Replacing the fundamental idea from Unix that everything is a file and instead relying on concepts from the database world a operating system that supports large scale distributed applications in the cloud can be built.
| Everything is a file
The core principles suggested to achieve this is:
Store all application in tables in a distributed database Store all OS state in tables in a distributed database.</description></item><item><title>Bloom filters</title><link>https://www.njordy.com/2023/05/17/bloom_filter/</link><pubDate>Thu, 18 May 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/05/17/bloom_filter/</guid><description>Bloom filters is a probabilistic data structure, which is space efficient. Bloom filters can be used to quickly check if a value don&amp;rsquo;t exists or might exists in a set, false positives are possible(with a low likelihood) but false negatives are not possible. The time to check if an element exsist or add an element is also constant O(k), where k is the number of hash functions(we will covert this later).</description></item><item><title>Setting up a Basic dbt Development Container for BigQuery in GCP</title><link>https://www.njordy.com/2023/04/29/setting-up-basic-dbt-dev-container/</link><pubDate>Sat, 29 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/04/29/setting-up-basic-dbt-dev-container/</guid><description>In this post, you will learn how to set up a basic dbt project in Google Cloud Platform (GCP) and share a development container to kickstart your project. While there are numerous blog posts out there about dbt and BigQuery, none of them share how to set it up in a development container without using any of the dbt-cloud services (at least to my knowledge).
Setting upp your enviorment Set up a gcp project/ or take one you allready have</description></item><item><title>Go memory arenas for apache arrow, Part 2</title><link>https://www.njordy.com/2023/04/14/apache-arrow-memory-arena-go-part-2/</link><pubDate>Fri, 14 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/04/14/apache-arrow-memory-arena-go-part-2/</guid><description>This blog post will continue to try to dive down in to apache arrow and specifically the Go memory allocation for Apache arrow. This is a follow up to Go memory arenas for apache arrow, Part 1.
First of all why do we want to manage memory manually instead of using the GC? One of arrows key features is it support to share memory with out copy between programs however for a GC collected language this will not work that great.</description></item><item><title>Push based query engine</title><link>https://www.njordy.com/2023/05/17push_based_query_engine/</link><pubDate>Fri, 14 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/05/17push_based_query_engine/</guid><description>In this blog post we will dive down in to the difference between push based vs pull based query engines. As simple as is sounds push based is based upon that data is pushed from the sink through the different operators, this is used by snowflake and argued to be superior for OLAP which we will dive deeper into. Pull based have been around for a longer time and is based upon that data is pulled from the sink up through the operators, this is also known as theVolcano Iterator Model</description></item><item><title>Go memory arenas for apache arrow, Part 1</title><link>https://www.njordy.com/2023/03/23/apache-arrow-memory-arena-go/</link><pubDate>Wed, 29 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/03/23/apache-arrow-memory-arena-go/</guid><description>This blog post will try to dive down in to apache arrow and specifically the Go memory allocation for Apache arrow. Apache arrow state that they allow for the following types of memory allocations:
Go default allocations(standard go GC collected memory) CGo allocator(memory allocated through CG0) Checked Memory Allocator Will deep dive in to these once in a follow up blog post. Today the goal is to extend with a new memory allocator, mostly becuase I read up on go memory arena which where introduced in to 1.</description></item><item><title>How to faster apply for a new job</title><link>https://www.njordy.com/2023/03/23/chatgpt3-cover-letter-generator/</link><pubDate>Tue, 28 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/03/23/chatgpt3-cover-letter-generator/</guid><description>Applying for jobs are fun, but it is not fun to write cover letters at least not compare to hacking on some new open source tool or testing out something new. Therefore the goal is to reduce the time to apply for a job thus the goal today is to generate cover letters. For this we will need the following:
CV, I will copy paste mine from linkedin(minimal effort and I spend way to much time on linkedin so it is up to date) Job add(will take one from linkedin that sounds interesting) Get the CV.</description></item><item><title>Awesome go resources</title><link>https://www.njordy.com/2023/03/23/awesome-go/</link><pubDate>Thu, 23 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/03/23/awesome-go/</guid><description>This blog post is a collection of awesome go resource and will be continuously update. The goal is that each resource should be describe shortly as well.
Blogs:
Generics can make your Go code slower Effective go Go memory model inline Videos:
Obscure Go Optimisations A Guide to the Go Garbage Collector</description></item><item><title>Storing Kubeflow Pipeline Templates in GCP Artifact Registry</title><link>https://www.njordy.com/2023/03/23/storing-kubeflow-pipeline-templates-gcp-artifact-registry/</link><pubDate>Thu, 23 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/03/23/storing-kubeflow-pipeline-templates-gcp-artifact-registry/</guid><description>In this blog post, we will discuss how to store Kubeflow Pipeline templates in GCP Artifact Registry, enabling reusability and version control for your pipelines. Using Artifact Registry over Cloud Storage simplifies version control and allows for easier collaboration between single or multiple users.
The Kubeflow Pipelines SDK registry client is a new client interface that you can use with a compatible registry server (ensure you are using the correct KFP version), such as Artifact Registry, for version control of your Kubeflow Pipelines (KFP) templates.</description></item><item><title>Running a kubeflow pipeline on google vertex</title><link>https://www.njordy.com/2023/03/21/kubeflow-pipelines/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/03/21/kubeflow-pipelines/</guid><description>This blog post will go over how to build and run your very first kubeflow pipeline (kfp). In short, Kubeflow Pipelines is a platform for building and deploying portable, scalable machine learning (ML) workflows based on Docker containers.
There are a lot of possibilities to run the pipelines, but in this series, we will use gcp vertex pipelines. Vertex will be the runner, but the pipelines will follow the kubeflow conventions meaning you can run them on whatever platform at hand or host kubeflow on your own Kubernetes cluster.</description></item><item><title>Configuring Your Local Dev Container with GCP Default Credentials</title><link>https://www.njordy.com/2023/03/20/vs-code-dev-container-gcp-credentials/</link><pubDate>Mon, 20 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/03/20/vs-code-dev-container-gcp-credentials/</guid><description>This blog post provides a step-by-step guide for setting up your VS Code dev container to work with Google Cloud Platform (GCP) services and APIs by configuring default GCP credentials. By authenticating your application with your GCP credentials, you can access the necessary resources without requiring additional authentication steps, saving time and streamlining your development workflow.
Configuring Default GCP Credentials To use default credentials with GCP, you can follow the steps below:</description></item><item><title>Supercharge Your Development Workflow with VS Code Dev Containers</title><link>https://www.njordy.com/2023/03/18/dev-containers/</link><pubDate>Sat, 18 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/03/18/dev-containers/</guid><description>VS docker Dev Container Are you tired of dealing with messy, inconsistent development environments that slow down your workflow? Look no further than VS Code dev containers, a powerful feature in Visual Studio Code that can streamline your development process and improve consistency across different environments.
In this post, we&amp;rsquo;ll dive into what dev containers are and how you can use them to supercharge your development workflow. We&amp;rsquo;ll also walk through how to set up a dev container for a Python environment and you will get an understsnding how easy it is to get started.</description></item><item><title>Postgress extention using ChatGPT3</title><link>https://www.njordy.com/2023/03/11/postgress_extention_using_chatgpt3/</link><pubDate>Sat, 11 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/03/11/postgress_extention_using_chatgpt3/</guid><description>This blog post will dive into building postgres extensions using pgx in rust. In order to do something existing we will ride the hype curve and integrate ChatGPT3 into postgres.
TLDR: repo
Setup First step is to set up pgx:
$ cargo install --locked cargo-pgx $ cargo pgx init We will then create a new create using:
$ cargo pgx new my_extension $ cd my_extension Which should give you something like:</description></item><item><title>Go memory arena</title><link>https://www.njordy.com/2023/03/01/go_memory_arena/</link><pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/03/01/go_memory_arena/</guid><description>As part of the go 1.20 release memory areas where introduced to the standard lib but not mentioned in the release notes but is still being discussed as of 2023-03-02 here. Memory arenas allow users to allocate memory and are described by the docs as:
The arena package provides the ability to allocate memory for a collection of Go values and free that space manually all at once, safely. The purpose of this functionality is to improve efficiency: manually freeing memory before a garbage collection delays that cycle.</description></item><item><title>Triton shared memory and pinned memory</title><link>https://www.njordy.com/2023/02/25/triton_shared_memory/</link><pubDate>Sat, 25 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/02/25/triton_shared_memory/</guid><description>This blog post will go in to depth how to use shared memory together with nvidia triton and pinned memory for model serving. This will continue to build further on the other blog posts related to triton. First we will focuse on shared memory and then move over to also look in to pinned memory and why it matters.
Shared memory In the triton examples(python) shared memory is often abbreviated as shm.</description></item><item><title>Duckdb with hugo</title><link>https://www.njordy.com/2023/02/06/hugo-duckdb/</link><pubDate>Wed, 08 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/02/06/hugo-duckdb/</guid><description>Current hack to just get the stuff working.</description></item><item><title>Go compiler optimizations</title><link>https://www.njordy.com/2023/02/08/Profile-guided_inlining_optimization/</link><pubDate>Wed, 08 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/02/08/Profile-guided_inlining_optimization/</guid><description>This is based upon the new feature released in go v1.20 where the compiler can optimize using a pprof file.
In order to run the pprof we will use flags:
flag.Parse() if *cpuprofile != &amp;#34;&amp;#34; { f, err := os.Create(*cpuprofile) if err != nil { log.Fatal(err) } pprof.StartCPUProfile(f) defer pprof.StopCPUProfile() } more info can be found here.
In order to run the profiling use the following command:
go run main.go -cpuprofile=prof.</description></item><item><title>Shinylive app with hugo</title><link>https://www.njordy.com/2023/02/06/hugo-with-python-rshiny/</link><pubDate>Mon, 06 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/02/06/hugo-with-python-rshiny/</guid><description>Shinylive app with hugo This blog post is based upon RamiKrispin/shinylive where we will take a look in to using Shiny with python and leveraging WebAssembly to let it run in the browser with out a backend. This allows for interactive static webpages.
In order to add the a shiny app it needs to be deployed, in this case that is handled through github pages and lives within https://github.com/NikeNano/shinylive. The second step is to add the iframe:</description></item><item><title>Trition with post and pre processing</title><link>https://www.njordy.com/2023/02/01/Trition_with_post_and_pre_processing/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/02/01/Trition_with_post_and_pre_processing/</guid><description>Trition with post and pre processing. This is based upon this repo
In this blog post we will dig down in to how a Machine Learning(ML) model can be combined with pre and post processing steps using Nvidia triton. By combining the pre- and post processing the user can make a single call using GPRC or http. It should be noted that we in reality will not merge these processing steps in any way but link the calls together using Tritons ensemble functionality Triton support multiple different backends(processing functionality) and in this case we will use the tensorRT backend for the model serving and the python backend to add the pre and post processing business logic.</description></item><item><title>Trition with post and pre processing</title><link>https://www.njordy.com/2023/02/01/Trition_with_post_and_pre_processing/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2023/02/01/Trition_with_post_and_pre_processing/</guid><description>Prompt engineering With the rise of GPT-3 and Stable diffusion the concpet of promt engineering has gain more and more traction. According to wikipedia the task can be described as
Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called &amp;ldquo;prompt-based learning&amp;rdquo; or just &amp;ldquo;prompt learning&amp;rdquo;
Wikipedia Prompts are inputs for models that expect text as input however the output can very most famously images or text.</description></item><item><title>Welcome to the Blog</title><link>https://www.njordy.com/2022/07/17/hello-world/</link><pubDate>Sun, 17 Jul 2022 00:00:00 +0000</pubDate><guid>https://www.njordy.com/2022/07/17/hello-world/</guid><description> “Yeah It&amp;rsquo;s on. ”
Hello World!</description></item><item><title/><link>https://www.njordy.com/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.njordy.com/about/</guid><description>Niklas Niklas is a Software engineer(previously data scientist) working with battery manufacturing 🔋 . He loves learning new things and currently work on traceability for electrode manufacturing. Work is GO, python and SQL while night hacking currently is rust.
Some open source project Niklas has contributed to:
kubeflow pipelines argo workflows nvidia triton Johan Johan is a Machine Learning engineer working on forecasting and life time value modeling 🔎 .</description></item><item><title/><link>https://www.njordy.com/posts/2023-02-07-poor_mans_datalake/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.njordy.com/posts/2023-02-07-poor_mans_datalake/</guid><description>Poor mans datalake layout: post title: &amp;ldquo;Poor mans datalake&amp;rdquo; subtitle: &amp;ldquo;DuckDb&amp;rdquo; date: 2023-02-01 author: &amp;ldquo;Niklas Hansson&amp;rdquo; URL: &amp;ldquo;/2023/02/01/Trition_with_post_and_pre_processing/&amp;rdquo; This post is a deep dive playing with DuckDB doing a twist on Build a poor man’s data lake from scratch with DuckDB where we will do the following changes:
Use Minio instead of S3 DBT instead of dagster. We will host it on Kubernetes and set it up so it all run locally.</description></item></channel></rss>