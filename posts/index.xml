<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Njord tech blog</title><link>https://Njorda.github.io/posts/</link><description>Recent content in Posts on Njord tech blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 25 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://Njorda.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Triton shared memory and pinned memory</title><link>https://Njorda.github.io/2023/02/25/triton_shared_memory/</link><pubDate>Sat, 25 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/25/triton_shared_memory/</guid><description>This blog post will go in to depth how to use shared memory together with nvidia triton and pinned memory for model serving. This will continue to build further on the other blog posts related to triton. First we will focuse on shared memory and then move over to also look in to pinned memory and why it matters.
Shared memory In the triton examples(python) shared memory is often abbreviated as shm.</description></item><item><title>Duckdb with hugo</title><link>https://Njorda.github.io/2023/02/06/hugo-duckdb/</link><pubDate>Wed, 08 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/06/hugo-duckdb/</guid><description>Current hack to just get the stuff working.</description></item><item><title>Go compiler optimizations</title><link>https://Njorda.github.io/2023/02/08/Profile-guided_inlining_optimization/</link><pubDate>Wed, 08 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/08/Profile-guided_inlining_optimization/</guid><description>Copilie optimisation using pprof This is based upon the new feature released in go v1.20 where the compiler can optimize using a pprof file.
In order to run the pprof we will use flags:
flag.Parse() if *cpuprofile != &amp;#34;&amp;#34; { f, err := os.Create(*cpuprofile) if err != nil { log.Fatal(err) } pprof.StartCPUProfile(f) defer pprof.StopCPUProfile() } more info can be found here.
In order to run the profiling use the following command:</description></item><item><title>Shinylive app with hugo</title><link>https://Njorda.github.io/2023/02/06/hugo-with-python-rshiny/</link><pubDate>Mon, 06 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/06/hugo-with-python-rshiny/</guid><description>Shinylive app with hugo This blog post is based upon RamiKrispin/shinylive where we will take a look in to using Shiny with python and leveraging WebAssembly to let it run in the browser with out a backend. This allows for interactive static webpages.
In order to add the a shiny app it needs to be deployed, in this case that is handled through github pages and lives within https://github.com/NikeNano/shinylive. The second step is to add the iframe:</description></item><item><title>Trition with post and pre processing</title><link>https://Njorda.github.io/2023/02/01/Trition_with_post_and_pre_processing/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/01/Trition_with_post_and_pre_processing/</guid><description>Trition with post and pre processing. This is based upon this repo
In this blog post we will dig down in to how a Machine Learning(ML) model can be combined with pre and post processing steps using Nvidia triton. By combining the pre- and post processing the user can make a single call using GPRC or http. It should be noted that we in reality will not merge these processing steps in any way but link the calls together using Tritons ensemble functionality Triton support multiple different backends(processing functionality) and in this case we will use the tensorRT backend for the model serving and the python backend to add the pre and post processing business logic.</description></item><item><title>Trition with post and pre processing</title><link>https://Njorda.github.io/2023/02/01/Trition_with_post_and_pre_processing/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2023/02/01/Trition_with_post_and_pre_processing/</guid><description>Prompt engineering With the rise of GPT-3 and Stable diffusion the concpet of promt engineering has gain more and more traction. According to wikipedia the task can be described as
Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called &amp;ldquo;prompt-based learning&amp;rdquo; or just &amp;ldquo;prompt learning&amp;rdquo;
Wikipedia Prompts are inputs for models that expect text as input however the output can very most famously images or text.</description></item><item><title>Welcome to the Blog</title><link>https://Njorda.github.io/2022/07/17/hello-world/</link><pubDate>Sun, 17 Jul 2022 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/2022/07/17/hello-world/</guid><description> “Yeah It&amp;rsquo;s on. ”
Hello World!</description></item><item><title/><link>https://Njorda.github.io/posts/2023-02-07-poor_mans_datalake/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/posts/2023-02-07-poor_mans_datalake/</guid><description>Poor mans datalake layout: post title: &amp;ldquo;Poor mans datalake&amp;rdquo; subtitle: &amp;ldquo;DuckDb&amp;rdquo; date: 2023-02-01 author: &amp;ldquo;Niklas Hansson&amp;rdquo; URL: &amp;ldquo;/2023/02/01/Trition_with_post_and_pre_processing/&amp;rdquo; This post is a deep dive playing with DuckDB doing a twist on Build a poor man’s data lake from scratch with DuckDB where we will do the following changes:
Use Minio instead of S3 DBT instead of dagster. We will host it on Kubernetes and set it up so it all run locally.</description></item><item><title/><link>https://Njorda.github.io/posts/2023-03-02-memory-arena/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/posts/2023-03-02-memory-arena/</guid><description>&amp;mdash; layout: post title: &amp;ldquo;Go memory arena&amp;rdquo; subtitle: &amp;ldquo;Optimize the GC by not using it&amp;rdquo; date: 2023-03-01 author: &amp;ldquo;Niklas Hansson&amp;rdquo; URL: &amp;ldquo;/2023/03/01/go_memory_arena/&amp;rdquo; iframe: &amp;ldquo;https://nikenano.github.io/shinylive/&amp;quot; As part of the go 1.20 release memory areas where introduced to the standard lib but not mentioned in the release notes but is still being discussed as of 2023-03-02 here. Memory arenas allow users to allocate memory and are described by the docs as:
The arena package provides the ability to allocate memory for a collection of Go values and free that space manually all at once, safely.</description></item><item><title/><link>https://Njorda.github.io/posts/2023-03-08-model-drigt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Njorda.github.io/posts/2023-03-08-model-drigt/</guid><description>Read article Repeat experiment Test on the same datasets with nany ml. Goal validate the article.</description></item></channel></rss>